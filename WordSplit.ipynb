{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open ~ 1000 words about the great barrier reef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('greatbarrier.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the most basic possible tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = re.sub('[^a-zA-Z ]+','',text.lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for t in tokens:\n",
    "    if t in counts:\n",
    "        counts[t]+=1\n",
    "    else:\n",
    "        counts[t]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take the largest last few\n",
    "we do this by sorting the list in reverse count order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 77),\n",
       " ('of', 38),\n",
       " ('in', 23),\n",
       " ('reef', 23),\n",
       " ('to', 20),\n",
       " ('and', 18),\n",
       " ('reefs', 17),\n",
       " ('great', 14),\n",
       " ('barrier', 13),\n",
       " ('years', 12)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v) for k,v in counts.items()],key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this stage, we still clearly have some work to do: we have a bunch of 'boring' words the, of, in etc and we have 'reefs' and 'reef' as two separate words - to note two really basic problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(nltk.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also do this\n",
    "nltk_tokens=nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "stopwords =  stopwords.words('english')\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_counts = {}\n",
    "for t in tokens:\n",
    "    if t in stopwords:\n",
    "        # ignore this word and go to next elem in loop\n",
    "        continue\n",
    "    elif t in better_counts:\n",
    "        better_counts[t]+=1\n",
    "    else:\n",
    "        better_counts[t]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how much better have we done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reef', 23),\n",
       " ('reefs', 17),\n",
       " ('great', 14),\n",
       " ('barrier', 13),\n",
       " ('years', 12),\n",
       " ('sea', 10),\n",
       " ('ago', 9),\n",
       " ('level', 8),\n",
       " ('coral', 8),\n",
       " ('found', 7),\n",
       " ('island', 7),\n",
       " ('islands', 7),\n",
       " ('growth', 5),\n",
       " ('queensland', 5),\n",
       " ('grow', 5)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v) for k,v in better_counts.items()],key=lambda x: x[1], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this looks pretty good except for 'reefs' and 'reef', 'island' and 'islands' - for this we need stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_better_counts = {}\n",
    "for t in tokens:\n",
    "    w = stemmer.stem(t)\n",
    "    if w in stopwords:\n",
    "        continue\n",
    "    elif w in even_better_counts:\n",
    "        even_better_counts[w]+=1\n",
    "    else:\n",
    "        even_better_counts[w]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'reef', 40),\n",
       " (u'year', 15),\n",
       " (u'great', 14),\n",
       " (u'island', 14),\n",
       " (u'barrier', 13),\n",
       " (u'coral', 11),\n",
       " (u'sea', 10),\n",
       " (u'level', 9),\n",
       " (u'ago', 9),\n",
       " (u'found', 7),\n",
       " (u'grow', 6),\n",
       " (u'sediment', 5),\n",
       " (u'growth', 5),\n",
       " (u'water', 5),\n",
       " (u'form', 5)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v) for k, v in even_better_counts.items()],\n",
    "       key=lambda x: x[1], \n",
    "       reverse=True\n",
    "       )[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    " - time series of sentiment\n",
    " - give each document a sentiment score\n",
    " - create full time series of sentiment/security\n",
    " - resample to create daily time series of sentiment/security\n",
    " \n",
    " - Are there any words with are particularly indicitave of a stock?\n",
    " - compute tf-idf statistic for each security and for each word -> visualise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
